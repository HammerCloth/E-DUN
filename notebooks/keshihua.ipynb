{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_feat, kernel_size, bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        m = []\n",
    "        for i in range(2):\n",
    "            m.append(nn.Conv2d(n_feat, n_feat, kernel_size, padding=(kernel_size // 2), bias=bias))\n",
    "            if bn:\n",
    "                m.append(nn.BatchNorm2d(n_feat))\n",
    "            if i == 0:\n",
    "                m.append(act)\n",
    "\n",
    "        self.body = nn.Sequential(*m)\n",
    "        self.res_scale = res_scale"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_feat, kernel_size, bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        m = []\n",
    "        for i in range(2):\n",
    "            m.append(nn.Conv2d(n_feat, n_feat, kernel_size, padding=(kernel_size // 2), bias=bias))\n",
    "            if bn:\n",
    "                m.append(nn.BatchNorm2d(n_feat))\n",
    "            if i == 0:\n",
    "                m.append(act)\n",
    "\n",
    "        self.body = nn.Sequential(*m)\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "    def forward(self, x):  # x(n_feat) -> res(n_feat)\n",
    "        res = self.body(x).mul(self.res_scale)\n",
    "        res += x\n",
    "        return res\n",
    "\n",
    "\n",
    "class EncodingBlock(nn.Module):\n",
    "    def __init__(self, ch_in):\n",
    "        super(EncodingBlock, self).__init__()\n",
    "\n",
    "        body = [\n",
    "            nn.Conv2d(ch_in, 64, kernel_size=3, padding=3 // 2),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=3 // 2)\n",
    "        ]\n",
    "        self.body = nn.Sequential(*body)\n",
    "        self.down = nn.Conv2d(128, 64, kernel_size=3, stride=2, padding=3 // 2)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):  # input -> f_e(128),down(64)\n",
    "        f_e = self.body(input)\n",
    "        down = self.act(self.down(f_e))\n",
    "        return f_e, down\n",
    "\n",
    "\n",
    "class EncodingBlockEnd(nn.Module):\n",
    "    def __init__(self, ch_in):\n",
    "        super(EncodingBlockEnd, self).__init__()\n",
    "\n",
    "        head = [\n",
    "            nn.Conv2d(in_channels=ch_in, out_channels=64, kernel_size=3, padding=3 // 2),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        body = [\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "        ]\n",
    "        tail = [\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=3 // 2)\n",
    "        ]\n",
    "        self.head = nn.Sequential(*head)\n",
    "        self.body = nn.Sequential(*body)\n",
    "        self.tail = nn.Sequential(*tail)\n",
    "\n",
    "    def forward(self, input):  # input -> f_e(128)\n",
    "        out = self.head(input)\n",
    "        f_e = self.body(out) + out\n",
    "        f_e = self.tail(f_e)\n",
    "        return f_e\n",
    "\n",
    "\n",
    "class DecodingBlock(nn.Module):\n",
    "    def __init__(self, ch_in):\n",
    "        super(DecodingBlock, self).__init__()\n",
    "\n",
    "        body = [\n",
    "            nn.Conv2d(in_channels=ch_in, out_channels=64, kernel_size=3, padding=3 // 2),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1, padding=1 // 2)\n",
    "        ]\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.act = nn.ReLU()\n",
    "        self.body = nn.Sequential(*body)\n",
    "\n",
    "    def forward(self, input, map):  # input(128),map(128) -> out(256)\n",
    "        # 保证逆向卷积出来的shape和map一致\n",
    "        up = self.up(input, output_size=[input.shape[0], input.shape[1], map.shape[2], map.shape[3]])\n",
    "        up = self.act(up)\n",
    "        out = torch.cat((up, map), 1)  # 在channel 纬度上\n",
    "        out = self.body(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecodingBlockEnd(nn.Module):\n",
    "    def __init__(self, ch_in):\n",
    "        super(DecodingBlockEnd, self).__init__()\n",
    "\n",
    "        body = [\n",
    "            nn.Conv2d(ch_in, 64, kernel_size=3, padding=3 // 2),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "            ResBlock(n_feat=64, kernel_size=3),\n",
    "        ]\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.act = nn.ReLU()\n",
    "        self.body = nn.Sequential(*body)\n",
    "\n",
    "    def forward(self, input, map):  # input(128),map(128) -> out(64)\n",
    "        # 保证逆向卷积出来的shape和map一致\n",
    "        up = self.up(input, output_size=[input.shape[0], input.shape[1], map.shape[2], map.shape[3]])\n",
    "        out = self.act(up)\n",
    "        out = torch.cat((out, map), 1)  # 在channel 纬度上\n",
    "        out = self.body(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Encoding_block1 = EncodingBlock(64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "EncodingBlock(\n  (body): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): ResBlock(\n      (body): Sequential(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace)\n        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n    )\n    (3): ResBlock(\n      (body): Sequential(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace)\n        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n    )\n    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (down): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (act): ReLU()\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoding_block1.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "x = torch.randn(1,64,128,128)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal as signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CandyNet(nn.Module):\n",
    "    def __init__(self, threshold=10.0, use_cuda=False):\n",
    "        super(CandyNet, self).__init__()\n",
    "\n",
    "        self.threshold = threshold\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        filter_size = 5\n",
    "        generated_filters = signal.gaussian(filter_size, std=1.0).reshape([1, filter_size])\n",
    "\n",
    "        self.gaussian_filter_horizontal = nn.Conv2d(1, 1, kernel_size=(1, filter_size), padding=(0, filter_size // 2))\n",
    "        self.gaussian_filter_horizontal.weight.data.copy_(torch.from_numpy(generated_filters))\n",
    "        self.gaussian_filter_horizontal.bias.data.copy_(torch.from_numpy(np.array([0.0])))\n",
    "\n",
    "        self.gaussian_filter_vertical = nn.Conv2d(1, 1, kernel_size=(filter_size, 1), padding=(filter_size // 2, 0))\n",
    "        self.gaussian_filter_vertical.weight.data.copy_(torch.from_numpy(generated_filters.T))\n",
    "        self.gaussian_filter_vertical.bias.data.copy_(torch.from_numpy(np.array([0.0])))\n",
    "\n",
    "        sobel_filter = np.array([[1, 0, -1],\n",
    "                                 [2, 0, -2],\n",
    "                                 [1, 0, -1]])\n",
    "\n",
    "        self.sobel_filter_horizontal = nn.Conv2d(1, 1, kernel_size=sobel_filter.shape,\n",
    "                                                 padding=sobel_filter.shape[0] // 2)\n",
    "        self.sobel_filter_horizontal.weight.data.copy_(torch.from_numpy(sobel_filter))\n",
    "        self.sobel_filter_horizontal.bias.data.copy_(torch.from_numpy(np.array([0.0])))\n",
    "\n",
    "        self.sobel_filter_vertical = nn.Conv2d(1, 1, kernel_size=sobel_filter.shape, padding=sobel_filter.shape[0] // 2)\n",
    "        self.sobel_filter_vertical.weight.data.copy_(torch.from_numpy(sobel_filter.T))\n",
    "        self.sobel_filter_vertical.bias.data.copy_(torch.from_numpy(np.array([0.0])))\n",
    "\n",
    "        # filters were flipped manually\n",
    "        filter_0 = np.array([[0, 0, 0],\n",
    "                             [0, 1, -1],\n",
    "                             [0, 0, 0]])\n",
    "\n",
    "        filter_45 = np.array([[0, 0, 0],\n",
    "                              [0, 1, 0],\n",
    "                              [0, 0, -1]])\n",
    "\n",
    "        filter_90 = np.array([[0, 0, 0],\n",
    "                              [0, 1, 0],\n",
    "                              [0, -1, 0]])\n",
    "\n",
    "        filter_135 = np.array([[0, 0, 0],\n",
    "                               [0, 1, 0],\n",
    "                               [-1, 0, 0]])\n",
    "\n",
    "        filter_180 = np.array([[0, 0, 0],\n",
    "                               [-1, 1, 0],\n",
    "                               [0, 0, 0]])\n",
    "\n",
    "        filter_225 = np.array([[-1, 0, 0],\n",
    "                               [0, 1, 0],\n",
    "                               [0, 0, 0]])\n",
    "\n",
    "        filter_270 = np.array([[0, -1, 0],\n",
    "                               [0, 1, 0],\n",
    "                               [0, 0, 0]])\n",
    "\n",
    "        filter_315 = np.array([[0, 0, -1],\n",
    "                               [0, 1, 0],\n",
    "                               [0, 0, 0]])\n",
    "\n",
    "        all_filters = np.stack(\n",
    "            [filter_0, filter_45, filter_90, filter_135, filter_180, filter_225, filter_270, filter_315])\n",
    "\n",
    "        self.directional_filter = nn.Conv2d(1, 8, kernel_size=filter_0.shape, padding=filter_0.shape[-1] // 2)\n",
    "        self.directional_filter.weight.data.copy_(torch.from_numpy(all_filters[:, None, ...]))\n",
    "        self.directional_filter.bias.data.copy_(torch.from_numpy(np.zeros(shape=(all_filters.shape[0],))))\n",
    "\n",
    "    def forward(self, img):  # (batch,channel,height, width)\n",
    "\n",
    "        batch = img.shape[0]\n",
    "        img_r = img[:, 0:1]  # batch,1,height, width\n",
    "        img_g = img[:, 1:2]  # batch,1,height, width\n",
    "        img_b = img[:, 2:3]  # batch,1,height, width\n",
    "\n",
    "        blur_horizontal = self.gaussian_filter_horizontal(img_r)  # batch,1,height,width\n",
    "        blurred_img_r = self.gaussian_filter_vertical(blur_horizontal)  # batch,1,height,width\n",
    "        blur_horizontal = self.gaussian_filter_horizontal(img_g)  # batch,1,height,width\n",
    "        blurred_img_g = self.gaussian_filter_vertical(blur_horizontal)  # batch,1,height,width\n",
    "        blur_horizontal = self.gaussian_filter_horizontal(img_b)  # batch,1,height,width\n",
    "        blurred_img_b = self.gaussian_filter_vertical(blur_horizontal)  # batch,1,height,width\n",
    "\n",
    "        blurred_img = torch.stack([blurred_img_r, blurred_img_g, blurred_img_b], dim=1)  # batch,1,height,width\n",
    "        blurred_img = torch.stack([torch.squeeze(blurred_img)])  # batch,1,height,width\n",
    "\n",
    "        grad_x_r = self.sobel_filter_horizontal(blurred_img_r)  # batch,1,height,width\n",
    "        grad_y_r = self.sobel_filter_vertical(blurred_img_r)  # batch,1,height,width\n",
    "        grad_x_g = self.sobel_filter_horizontal(blurred_img_g)  # batch,1,height,width\n",
    "        grad_y_g = self.sobel_filter_vertical(blurred_img_g)  # batch,1,height,width\n",
    "        grad_x_b = self.sobel_filter_horizontal(blurred_img_b)  # batch,1,height,width\n",
    "        grad_y_b = self.sobel_filter_vertical(blurred_img_b)  # batch,1,height,width\n",
    "\n",
    "        # COMPUTE THICK EDGES\n",
    "        grad_mag = torch.sqrt(grad_x_r ** 2 + grad_y_r ** 2)  # batch,1,height,width\n",
    "        grad_mag += torch.sqrt(grad_x_g ** 2 + grad_y_g ** 2)  # batch,1,height,width\n",
    "        grad_mag += torch.sqrt(grad_x_b ** 2 + grad_y_b ** 2)  # batch,1,height,width\n",
    "        grad_orientation = (  # batch,1,height,width\n",
    "                torch.atan2(grad_y_r + grad_y_g + grad_y_b, grad_x_r + grad_x_g + grad_x_b) * (180.0 / 3.14159))\n",
    "        grad_orientation += 180.0  # batch,1,height,width\n",
    "        grad_orientation = torch.round(grad_orientation / 45.0) * 45.0  # batch,1,height,width\n",
    "\n",
    "        # THIN EDGES (NON-MAX SUPPRESSION)\n",
    "\n",
    "        all_filtered = self.directional_filter(grad_mag)  # batch,8,height,width\n",
    "        inidices_positive = (grad_orientation / 45) % 8  # batch,1,height,width\n",
    "        inidices_negative = ((grad_orientation / 45) + 4) % 8  # batch,1,height,width\n",
    "\n",
    "        height = inidices_positive.size()[2]\n",
    "        width = inidices_positive.size()[3]\n",
    "        pixel_count = height * width\n",
    "\n",
    "        pixel_range = torch.FloatTensor([range(pixel_count)])  # batch,pixel_range\n",
    "        if self.use_cuda:\n",
    "            pixel_range = torch.cuda.FloatTensor([range(pixel_count)])\n",
    "\n",
    "        indices = (  # batch,pixel_range\n",
    "                inidices_positive.view(\n",
    "                    inidices_positive.shape[0],\n",
    "                    pixel_count).data * pixel_count + pixel_range)\n",
    "\n",
    "        channel_select_filtered_positive = torch.ones(batch, 1, height, width)  # batch, 1, height, width\n",
    "        for i in range(batch):\n",
    "            channel_select_filtered_positive_temp = all_filtered[i].view(-1)[indices[i].long()].view(1, height, width)\n",
    "            channel_select_filtered_positive[i] = channel_select_filtered_positive_temp\n",
    "\n",
    "        indices = (  # batch,pixel_range\n",
    "                inidices_negative.view(\n",
    "                    inidices_negative.shape[0],\n",
    "                    pixel_count).data * pixel_count + pixel_range)\n",
    "\n",
    "        channel_select_filtered_negative = torch.ones(batch, 1, height, width)  # batch, 1, height, width\n",
    "        for i in range(batch):\n",
    "            channel_select_filtered_negative_temp = all_filtered[i].view(-1)[indices[i].long()].view(1, height, width)\n",
    "            channel_select_filtered_negative[i] = channel_select_filtered_negative_temp\n",
    "\n",
    "        channel_select_filtered = torch.stack(  # batch, 2, height, width\n",
    "            [channel_select_filtered_positive, channel_select_filtered_negative], dim=1)\n",
    "\n",
    "        is_max = channel_select_filtered.min(dim=1)[0] > 0.0\n",
    "\n",
    "        thin_edges = grad_mag.clone()\n",
    "        thin_edges[is_max == 0] = 0.0\n",
    "\n",
    "        # THRESHOLD\n",
    "\n",
    "        thresholded = thin_edges.clone()\n",
    "        thresholded[thin_edges < self.threshold] = 0.0\n",
    "\n",
    "        early_threshold = grad_mag.clone()\n",
    "        early_threshold[grad_mag < self.threshold] = 0.0\n",
    "\n",
    "        assert grad_mag.size() == grad_orientation.size() == thin_edges.size() == thresholded.size() == early_threshold.size()\n",
    "\n",
    "        return thresholded\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    CandyNet()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        Encoding_block1,\n",
    "        x,\n",
    "        'test.onnx',\n",
    "        #opset_version=11,\n",
    "        input_names=['input'],\n",
    "        output_names=['output']\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draw.py    out.log      test.onnx        Untitled2.ipynb\r\n",
      "nohup.out  python.log3  Untitled1.ipynb  Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnx'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-6f9566fa2ea7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0monnx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'onnx'"
     ]
    }
   ],
   "source": [
    "import onnx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvUp(nn.Module):\n",
    "\n",
    "    def __init__(self, ch_in, up_factor):\n",
    "\n",
    "        super(ConvUp, self).__init__()\n",
    "\n",
    "        body = [\n",
    "            nn.Conv2d(ch_in, 64, kernel_size=3, padding=3 // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=3 // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=3 // 2),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "\n",
    "        if up_factor == 2:\n",
    "            modules_tail = [\n",
    "                nn.ConvTranspose2d(64, 64, kernel_size=3, stride=up_factor, padding=1, output_padding=1),\n",
    "                nn.Conv2d(64, ch_in, 3, padding=3 // 2, bias=True)\n",
    "            ]\n",
    "        elif up_factor == 3:\n",
    "            modules_tail = [\n",
    "                nn.ConvTranspose2d(64, 64, kernel_size=3, stride=up_factor, padding=0, output_padding=0),\n",
    "                nn.Conv2d(64, ch_in, 3, padding=3 // 2, bias=True)\n",
    "            ]\n",
    "\n",
    "        elif up_factor == 4:\n",
    "            modules_tail = [\n",
    "                nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.Conv2d(64, ch_in, 3, padding=3 // 2, bias=True)\n",
    "            ]\n",
    "\n",
    "        self.body = nn.Sequential(*body)\n",
    "        self.tail = nn.Sequential(*modules_tail)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        output = self.body(input)\n",
    "        output = self.tail(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class ConvDown(nn.Module):\n",
    "\n",
    "    def __init__(self, ch_in, up_factor):\n",
    "\n",
    "        super(ConvDown, self).__init__()\n",
    "\n",
    "        body = [\n",
    "            nn.Conv2d(ch_in, 64, kernel_size=3, padding=3 // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=3 // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=3 // 2),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "\n",
    "        if up_factor == 4:\n",
    "            modules_tail = [\n",
    "                nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=2),\n",
    "                nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=2),\n",
    "                nn.Conv2d(64, ch_in, kernel_size=3, padding=3 // 2, bias=True)\n",
    "            ]\n",
    "        elif up_factor == 3:\n",
    "            modules_tail = [\n",
    "                nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=up_factor),\n",
    "                nn.Conv2d(64, ch_in, kernel_size=3, padding=3 // 2, bias=True)\n",
    "            ]\n",
    "        elif up_factor == 2:\n",
    "            modules_tail = [\n",
    "                nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=up_factor),\n",
    "                nn.Conv2d(64, ch_in, kernel_size=3, padding=3 // 2, bias=True)\n",
    "            ]\n",
    "\n",
    "        self.body = nn.Sequential(*body)\n",
    "        self.tail = nn.Sequential(*modules_tail)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        out = self.body(input)\n",
    "        out = self.tail(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class E_DUN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(E_DUN, self).__init__()\n",
    "\n",
    "        self.channel0 = args.n_colors\n",
    "        self.up_factor = args.scale[0]\n",
    "        self.patch_size = args.patch_size\n",
    "        self.batch_size = int(args.batch_size / args.n_GPUs)\n",
    "\n",
    "        self.Encoding_block1 = EncodingBlock(64)\n",
    "        self.Encoding_block2 = EncodingBlock(64)\n",
    "        self.Encoding_block3 = EncodingBlock(64)\n",
    "        self.Encoding_block4 = EncodingBlock(64)\n",
    "\n",
    "        self.Encoding_block_end = EncodingBlockEnd(64)\n",
    "\n",
    "        self.Decoding_block1 = DecodingBlock(256)\n",
    "        self.Decoding_block2 = DecodingBlock(256)\n",
    "        self.Decoding_block3 = DecodingBlock(256)\n",
    "        self.Decoding_block4 = DecodingBlock(256)\n",
    "\n",
    "        self.feature_decoding_end = DecodingBlockEnd(256)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        self.construction = nn.Conv2d(64, 3, 3, padding=1)\n",
    "\n",
    "        G0 = 64\n",
    "        kSize = 3\n",
    "        T = 4\n",
    "        self.Fe_e = nn.ModuleList(\n",
    "            [nn.Sequential(*[\n",
    "                nn.Conv2d(3, G0, kSize, padding=(kSize - 1) // 2, stride=1),\n",
    "                nn.Conv2d(G0, G0, kSize, padding=(kSize - 1) // 2, stride=1)\n",
    "            ]) for _ in range(T)])\n",
    "\n",
    "        self.RNNF = nn.ModuleList(\n",
    "            [nn.Sequential(*[\n",
    "                nn.Conv2d((i + 2) * G0, G0, 1, padding=0, stride=1),\n",
    "                nn.Conv2d(G0, G0, kSize, padding=(kSize - 1) // 2, stride=1),\n",
    "                self.act,\n",
    "                nn.Conv2d(64, 3, 3, padding=1)\n",
    "            ]) for i in range(T)])\n",
    "\n",
    "        self.Fe_f = nn.ModuleList(\n",
    "            [nn.Sequential(*[\n",
    "                nn.Conv2d((2 * i + 3) * G0, G0, 1, padding=0, stride=1)\n",
    "            ]) for i in range(T - 1)])\n",
    "\n",
    "        self.eta = nn.ParameterList([nn.Parameter(torch.tensor(0.5)) for _ in range(T)])\n",
    "        self.delta = nn.ParameterList([nn.Parameter(torch.tensor(0.1)) for _ in range(T)])\n",
    "\n",
    "        self.conv_up = ConvUp(3, self.up_factor)\n",
    "        self.conv_down = ConvDown(3, self.up_factor)\n",
    "\n",
    "        self.candy = CandyNet(3).eval()  # candy算子不需要迭代内部系数\n",
    "\n",
    "    def forward(self, y):  # [batch_size ,3 ,7 ,270 ,480] ;\n",
    "        fea_list = []\n",
    "        V_list = []\n",
    "        outs = []\n",
    "\n",
    "        x_texture = torch.nn.functional.interpolate(\n",
    "            y, scale_factor=self.up_factor, mode='bilinear', align_corners=False)\n",
    "        x_edge = self.candy(x_texture)\n",
    "        x = x_edge + x_texture  # 这里可以增加一些倍数，直接相加可能会存在问题\n",
    "\n",
    "        for i in range(len(self.Fe_e)):\n",
    "            # --------------------denoising module------------------------\n",
    "            fea = self.Fe_e[i](x_texture)\n",
    "            fea_list.append(fea)\n",
    "            if i != 0:\n",
    "                fea = self.Fe_f[i - 1](torch.cat(fea_list, 1))\n",
    "            encode0, down0 = self.Encoding_block1(fea)\n",
    "            encode1, down1 = self.Encoding_block2(down0)\n",
    "            encode2, down2 = self.Encoding_block3(down1)\n",
    "            encode3, down3 = self.Encoding_block4(down2)\n",
    "\n",
    "            media_end = self.Encoding_block_end(down3)\n",
    "\n",
    "            decode3 = self.Decoding_block1(media_end, encode3)\n",
    "            decode2 = self.Decoding_block2(decode3, encode2)\n",
    "            decode1 = self.Decoding_block3(decode2, encode1)\n",
    "            decode0 = self.feature_decoding_end(decode1, encode0)\n",
    "\n",
    "            fea_list.append(decode0)\n",
    "            V_list.append(decode0)\n",
    "            if i == 0:\n",
    "                decode0 = self.construction(self.act(decode0))\n",
    "            else:\n",
    "                decode0 = self.RNNF[i - 1](torch.cat(V_list, 1))\n",
    "            v = x_texture + decode0\n",
    "\n",
    "            # --------------------texture module--------------------------\n",
    "            x_texture = x_texture - self.delta[i] * (\n",
    "                    self.conv_up(self.conv_down(x) - y) + self.eta[i] * (x - v))\n",
    "\n",
    "            # -----------------------edge module--------------------------\n",
    "            x_edge = self.candy(x)\n",
    "            x = x_edge + x_texture  # 这里可以增加一些倍数，直接相加可能会存在问题\n",
    "\n",
    "            outs.append(x)\n",
    "\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        self.n_colors = 3\n",
    "        self.scale = [2]\n",
    "        self.patch_size = 2\n",
    "        self.batch_size = 1\n",
    "        self.n_GPUs = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "args = test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "E_DUN(\n  (Encoding_block1): EncodingBlock(\n    (body): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (down): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n  )\n  (Encoding_block2): EncodingBlock(\n    (body): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (down): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n  )\n  (Encoding_block3): EncodingBlock(\n    (body): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (down): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n  )\n  (Encoding_block4): EncodingBlock(\n    (body): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (down): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n  )\n  (Encoding_block_end): EncodingBlockEnd(\n    (head): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n    )\n    (body): Sequential(\n      (0): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (1): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (5): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (6): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (7): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (8): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (9): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (10): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (11): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (12): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (13): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (14): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (15): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (16): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (17): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (tail): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (Decoding_block1): DecodingBlock(\n    (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n    (body): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (Decoding_block2): DecodingBlock(\n    (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n    (body): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (Decoding_block3): DecodingBlock(\n    (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n    (body): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (Decoding_block4): DecodingBlock(\n    (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n    (body): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (feature_decoding_end): DecodingBlockEnd(\n    (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n    (body): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n  )\n  (act): ReLU()\n  (construction): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Fe_e): ModuleList(\n    (0): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (1): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (2): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (3): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (RNNF): ModuleList(\n    (0): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): ReLU()\n      (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (1): Sequential(\n      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): ReLU()\n      (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (2): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): ReLU()\n      (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (3): Sequential(\n      (0): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): ReLU()\n      (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (Fe_f): ModuleList(\n    (0): Sequential(\n      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (1): Sequential(\n      (0): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (2): Sequential(\n      (0): Conv2d(448, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (eta): ParameterList(\n      (0): Parameter containing: [torch.FloatTensor of size ]\n      (1): Parameter containing: [torch.FloatTensor of size ]\n      (2): Parameter containing: [torch.FloatTensor of size ]\n      (3): Parameter containing: [torch.FloatTensor of size ]\n  )\n  (delta): ParameterList(\n      (0): Parameter containing: [torch.FloatTensor of size ]\n      (1): Parameter containing: [torch.FloatTensor of size ]\n      (2): Parameter containing: [torch.FloatTensor of size ]\n      (3): Parameter containing: [torch.FloatTensor of size ]\n  )\n  (conv_up): ConvUp(\n    (body): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n    )\n    (tail): Sequential(\n      (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (conv_down): ConvDown(\n    (body): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n    )\n    (tail): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (candy): CandyNet(\n    (gaussian_filter_horizontal): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n    (gaussian_filter_vertical): Conv2d(1, 1, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n    (sobel_filter_horizontal): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (sobel_filter_vertical): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (directional_filter): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = E_DUN(args)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:122: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:132: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:134: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:142: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:144: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:162: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1,3,256,256)\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        x,\n",
    "        'test.onnx',\n",
    "        #opset_version=11,\n",
    "        input_names=['input'],\n",
    "        output_names=['output']\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "candy = CandyNet(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "CandyNet(\n  (gaussian_filter_horizontal): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n  (gaussian_filter_vertical): Conv2d(1, 1, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n  (sobel_filter_horizontal): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (sobel_filter_vertical): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (directional_filter): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[[[0.1353, 0.6065, 1.0000, 0.6065, 0.1353]]]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True),\n Parameter containing:\n tensor([[[[0.1353],\n           [0.6065],\n           [1.0000],\n           [0.6065],\n           [0.1353]]]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True),\n Parameter containing:\n tensor([[[[ 1.,  0., -1.],\n           [ 2.,  0., -2.],\n           [ 1.,  0., -1.]]]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True),\n Parameter containing:\n tensor([[[[ 1.,  2.,  1.],\n           [ 0.,  0.,  0.],\n           [-1., -2., -1.]]]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True),\n Parameter containing:\n tensor([[[[ 0.,  0.,  0.],\n           [ 0.,  1., -1.],\n           [ 0.,  0.,  0.]]],\n \n \n         [[[ 0.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0., -1.]]],\n \n \n         [[[ 0.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0., -1.,  0.]]],\n \n \n         [[[ 0.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [-1.,  0.,  0.]]],\n \n \n         [[[ 0.,  0.,  0.],\n           [-1.,  1.,  0.],\n           [ 0.,  0.,  0.]]],\n \n \n         [[[-1.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  0.]]],\n \n \n         [[[ 0., -1.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  0.]]],\n \n \n         [[[ 0.,  0., -1.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  0.]]]], requires_grad=True),\n Parameter containing:\n tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(candy.parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "for para in candy.parameters():\n",
    "    para.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[[[0.1353, 0.6065, 1.0000, 0.6065, 0.1353]]]]),\n Parameter containing:\n tensor([0.]),\n Parameter containing:\n tensor([[[[0.1353],\n           [0.6065],\n           [1.0000],\n           [0.6065],\n           [0.1353]]]]),\n Parameter containing:\n tensor([0.]),\n Parameter containing:\n tensor([[[[ 1.,  0., -1.],\n           [ 2.,  0., -2.],\n           [ 1.,  0., -1.]]]]),\n Parameter containing:\n tensor([0.]),\n Parameter containing:\n tensor([[[[ 1.,  2.,  1.],\n           [ 0.,  0.,  0.],\n           [-1., -2., -1.]]]]),\n Parameter containing:\n tensor([0.]),\n Parameter containing:\n tensor([[[[ 0.,  0.,  0.],\n           [ 0.,  1., -1.],\n           [ 0.,  0.,  0.]]],\n \n \n         [[[ 0.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0., -1.]]],\n \n \n         [[[ 0.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0., -1.,  0.]]],\n \n \n         [[[ 0.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [-1.,  0.,  0.]]],\n \n \n         [[[ 0.,  0.,  0.],\n           [-1.,  1.,  0.],\n           [ 0.,  0.,  0.]]],\n \n \n         [[[-1.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  0.]]],\n \n \n         [[[ 0., -1.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  0.]]],\n \n \n         [[[ 0.,  0., -1.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  0.]]]]),\n Parameter containing:\n tensor([0., 0., 0., 0., 0., 0., 0., 0.])]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(candy.parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "CandyNet(\n  (gaussian_filter_horizontal): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n  (gaussian_filter_vertical): Conv2d(1, 1, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n  (sobel_filter_horizontal): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (sobel_filter_vertical): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (directional_filter): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:122: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:132: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:134: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:142: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:144: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py:162: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py:501: UserWarning: ONNX export failed on ATen operator atan2 because torch.onnx.symbolic.atan2 does not exist\n",
      "  .format(op_name, op_name))\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py:501: UserWarning: ONNX export failed on ATen operator round because torch.onnx.symbolic.round does not exist\n",
      "  .format(op_name, op_name))\n",
      "/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py:501: UserWarning: ONNX export failed on ATen operator remainder because torch.onnx.symbolic.remainder does not exist\n",
      "  .format(op_name, op_name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ONNX export failed: Couldn't export operator aten::atan2\n\nDefined at:\n<ipython-input-8-6c7c0dfadad2>(108): forward\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/nn/modules/module.py(477): _slow_forward\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/nn/modules/module.py(487): __call__\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/jit/__init__.py(252): forward\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/nn/modules/module.py(489): __call__\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/jit/__init__.py(197): get_trace_graph\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py(192): _trace_and_get_graph_from_model\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py(224): _model_to_graph\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py(281): _export\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py(104): export\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/__init__.py(27): export\n<ipython-input-20-ef10e6136362>(8): <module>\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3343): run_code\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3263): run_ast_nodes\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3072): run_cell_async\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/async_helpers.py(68): _pseudo_sync_runner\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/interactiveshell.py(2895): _run_cell\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/interactiveshell.py(2867): run_cell\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/zmqshell.py(536): run_cell\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/ipkernel.py(306): do_execute\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(162): _fake_ctx_run\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(234): wrapper\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/kernelbase.py(545): execute_request\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(162): _fake_ctx_run\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(234): wrapper\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/kernelbase.py(268): dispatch_shell\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(162): _fake_ctx_run\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(234): wrapper\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/kernelbase.py(365): process_one\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(775): run\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(162): _fake_ctx_run\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(814): inner\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/ioloop.py(741): _run_callback\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/ioloop.py(688): <lambda>\n/root/anaconda3/envs/aaa/lib/python3.6/asyncio/events.py(145): _run\n/root/anaconda3/envs/aaa/lib/python3.6/asyncio/base_events.py(1462): _run_once\n/root/anaconda3/envs/aaa/lib/python3.6/asyncio/base_events.py(442): run_forever\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/platform/asyncio.py(199): start\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/kernelapp.py(612): start\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/traitlets/config/application.py(664): launch_instance\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py(16): <module>\n/root/anaconda3/envs/aaa/lib/python3.6/runpy.py(85): _run_code\n/root/anaconda3/envs/aaa/lib/python3.6/runpy.py(193): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%input : Float(1, 3, 256, 256)\n      %1 : Float(1, 1, 1, 5)\n      %2 : Float(1)\n      %3 : Float(1, 1, 5, 1)\n      %4 : Float(1)\n      %5 : Float(1, 1, 3, 3)\n      %6 : Float(1)\n      %7 : Float(1, 1, 3, 3)\n      %8 : Float(1)\n      %9 : Float(8, 1, 3, 3)\n      %10 : Float(8)) {\n  %11 : Long() = onnx::Constant[value={0}](), scope: CandyNet\n  %12 : Tensor = onnx::Shape(%input), scope: CandyNet\n  %13 : Long() = onnx::Gather[axis=0](%12, %11), scope: CandyNet\n  %14 : Float(1, 3, 256, 256) = onnx::Slice[axes=[0], ends=[9223372036854775807], starts=[0]](%input), scope: CandyNet\n  %15 : Float(1!, 1, 256, 256) = onnx::Slice[axes=[1], ends=[1], starts=[0]](%14), scope: CandyNet\n  %16 : Float(1, 3, 256, 256) = onnx::Slice[axes=[0], ends=[9223372036854775807], starts=[0]](%input), scope: CandyNet\n  %17 : Float(1!, 1, 256, 256) = onnx::Slice[axes=[1], ends=[2], starts=[1]](%16), scope: CandyNet\n  %18 : Float(1, 3, 256, 256) = onnx::Slice[axes=[0], ends=[9223372036854775807], starts=[0]](%input), scope: CandyNet\n  %19 : Float(1!, 1, 256, 256) = onnx::Slice[axes=[1], ends=[3], starts=[2]](%18), scope: CandyNet\n  %20 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 5], pads=[0, 2, 0, 2], strides=[1, 1]](%15, %1, %2), scope: CandyNet/Conv2d[gaussian_filter_horizontal]\n  %21 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 1], pads=[2, 0, 2, 0], strides=[1, 1]](%20, %3, %4), scope: CandyNet/Conv2d[gaussian_filter_vertical]\n  %22 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 5], pads=[0, 2, 0, 2], strides=[1, 1]](%17, %1, %2), scope: CandyNet/Conv2d[gaussian_filter_horizontal]\n  %23 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 1], pads=[2, 0, 2, 0], strides=[1, 1]](%22, %3, %4), scope: CandyNet/Conv2d[gaussian_filter_vertical]\n  %24 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 5], pads=[0, 2, 0, 2], strides=[1, 1]](%19, %1, %2), scope: CandyNet/Conv2d[gaussian_filter_horizontal]\n  %25 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 1], pads=[2, 0, 2, 0], strides=[1, 1]](%24, %3, %4), scope: CandyNet/Conv2d[gaussian_filter_vertical]\n  %26 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%21, %5, %6), scope: CandyNet/Conv2d[sobel_filter_horizontal]\n  %27 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%21, %7, %8), scope: CandyNet/Conv2d[sobel_filter_vertical]\n  %28 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%23, %5, %6), scope: CandyNet/Conv2d[sobel_filter_horizontal]\n  %29 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%23, %7, %8), scope: CandyNet/Conv2d[sobel_filter_vertical]\n  %30 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%25, %5, %6), scope: CandyNet/Conv2d[sobel_filter_horizontal]\n  %31 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%25, %7, %8), scope: CandyNet/Conv2d[sobel_filter_vertical]\n  %32 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %33 : Float(1, 1, 256, 256) = onnx::Pow(%26, %32), scope: CandyNet\n  %34 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %35 : Float(1, 1, 256, 256) = onnx::Pow(%27, %34), scope: CandyNet\n  %36 : Float(1, 1, 256, 256) = onnx::Add(%33, %35), scope: CandyNet\n  %37 : Float(1, 1, 256, 256) = onnx::Sqrt(%36), scope: CandyNet\n  %38 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %39 : Float(1, 1, 256, 256) = onnx::Pow(%28, %38), scope: CandyNet\n  %40 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %41 : Float(1, 1, 256, 256) = onnx::Pow(%29, %40), scope: CandyNet\n  %42 : Float(1, 1, 256, 256) = onnx::Add(%39, %41), scope: CandyNet\n  %43 : Float(1, 1, 256, 256) = onnx::Sqrt(%42), scope: CandyNet\n  %44 : Float(1, 1, 256, 256) = onnx::Add(%37, %43), scope: CandyNet\n  %45 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %46 : Float(1, 1, 256, 256) = onnx::Pow(%30, %45), scope: CandyNet\n  %47 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %48 : Float(1, 1, 256, 256) = onnx::Pow(%31, %47), scope: CandyNet\n  %49 : Float(1, 1, 256, 256) = onnx::Add(%46, %48), scope: CandyNet\n  %50 : Float(1, 1, 256, 256) = onnx::Sqrt(%49), scope: CandyNet\n  %51 : Float(1, 1, 256, 256) = onnx::Add(%44, %50), scope: CandyNet\n  %52 : Float(1, 1, 256, 256) = onnx::Add(%27, %29), scope: CandyNet\n  %53 : Float(1, 1, 256, 256) = onnx::Add(%52, %31), scope: CandyNet\n  %54 : Float(1, 1, 256, 256) = onnx::Add(%26, %28), scope: CandyNet\n  %55 : Float(1, 1, 256, 256) = onnx::Add(%54, %30), scope: CandyNet\n  %56 : Float(1, 1, 256, 256) = aten::atan2(%53, %55), scope: CandyNet\n  %57 : Tensor = onnx::Constant[value={57.2958}]()\n  %58 : Tensor = onnx::Mul(%56, %57)\n  %59 : Tensor = onnx::Constant[value={180}]()\n  %60 : Tensor = onnx::Add(%58, %59)\n  %61 : Tensor = onnx::Constant[value={45}]()\n  %62 : Tensor = onnx::Div(%60, %61)\n  %63 : Float(1, 1, 256, 256) = aten::round(%62), scope: CandyNet\n  %64 : Tensor = onnx::Constant[value={45}]()\n  %65 : Tensor = onnx::Mul(%63, %64)\n  %66 : Tensor = onnx::Constant[value={45}]()\n  %67 : Tensor = onnx::Div(%65, %66)\n  %68 : Long() = onnx::Constant[value={8}](), scope: CandyNet\n  %69 : Float(1, 1, 256, 256) = aten::remainder(%67, %68), scope: CandyNet\n  %70 : Long() = onnx::Constant[value={2}](), scope: CandyNet\n  %71 : Tensor = onnx::Shape(%69), scope: CandyNet\n  %72 : Long() = onnx::Gather[axis=0](%71, %70), scope: CandyNet\n  %73 : Long() = onnx::Constant[value={3}](), scope: CandyNet\n  %74 : Tensor = onnx::Shape(%69), scope: CandyNet\n  %75 : Long() = onnx::Gather[axis=0](%74, %73), scope: CandyNet\n  %76 : Long() = onnx::Constant[value={1}](), scope: CandyNet\n  %77 : Tensor = onnx::Unsqueeze[axes=[0]](%13)\n  %78 : Tensor = onnx::Unsqueeze[axes=[0]](%76)\n  %79 : Tensor = onnx::Unsqueeze[axes=[0]](%72)\n  %80 : Tensor = onnx::Unsqueeze[axes=[0]](%75)\n  %81 : Tensor = onnx::Concat[axis=0](%77, %78, %79, %80)\n  %82 : Float(1, 1, 256, 256) = onnx::ConstantFill[dtype=1, input_as_shape=1, value=1](%81), scope: CandyNet\n  %83 : Long() = onnx::Constant[value={1}](), scope: CandyNet\n  %84 : Tensor = onnx::Unsqueeze[axes=[0]](%13)\n  %85 : Tensor = onnx::Unsqueeze[axes=[0]](%83)\n  %86 : Tensor = onnx::Unsqueeze[axes=[0]](%72)\n  %87 : Tensor = onnx::Unsqueeze[axes=[0]](%75)\n  %88 : Tensor = onnx::Concat[axis=0](%84, %85, %86, %87)\n  %89 : Float(1, 1, 256, 256) = onnx::ConstantFill[dtype=1, input_as_shape=1, value=1](%88), scope: CandyNet\n  %90 : Tensor = onnx::Unsqueeze[axes=[1]](%82), scope: CandyNet\n  %91 : Tensor = onnx::Unsqueeze[axes=[1]](%89), scope: CandyNet\n  %92 : Float(1, 2, 1, 256, 256) = onnx::Concat[axis=1](%90, %91), scope: CandyNet\n  %93 : Float(1, 1, 256, 256), %94 : Long(1, 1, 256, 256) = onnx::ATen[dim=1, keepdim=0, operator=\"min\"](%92), scope: CandyNet\n  %95 : Tensor = onnx::Constant[value={0}](), scope: CandyNet\n  %96 : Byte(1, 1, 256, 256) = onnx::Greater(%93, %95), scope: CandyNet\n  %97 : Long() = onnx::Constant[value={0}](), scope: CandyNet\n  %98 : Byte(1, 1, 256, 256) = onnx::Equal(%96, %97), scope: CandyNet\n  %99 : Float() = onnx::Constant[value={0}]()\n  %100 : Byte(1, 1, 256, 256) = onnx::Cast[to=2](%98), scope: CandyNet\n  %101 : Long() = onnx::Constant[value={0}](), scope: CandyNet\n  %102 : Float(1, 1, 256, 256) = onnx::ATen[operator=\"index_put\"](%51, %100, %99, %101), scope: CandyNet\n  %103 : Tensor = onnx::Constant[value={3}](), scope: CandyNet\n  %104 : Byte(1, 1, 256, 256) = onnx::Less(%102, %103), scope: CandyNet\n  %105 : Float() = onnx::Constant[value={0}]()\n  %106 : Byte(1, 1, 256, 256) = onnx::Cast[to=2](%104), scope: CandyNet\n  %107 : Long() = onnx::Constant[value={0}](), scope: CandyNet\n  %108 : Float(1, 1, 256, 256) = onnx::ATen[operator=\"index_put\"](%102, %106, %105, %107), scope: CandyNet\n  return (%108);\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-ef10e6136362>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0;34m'candy.onnx'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0;31m#opset_version=11,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m         \u001B[0minput_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'input'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m         \u001B[0;31m#output_names=['output']\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     )\n",
      "\u001B[0;32m~/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/__init__.py\u001B[0m in \u001B[0;36mexport\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mexport\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[0;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0monnx\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexport\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py\u001B[0m in \u001B[0;36mexport\u001B[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type)\u001B[0m\n\u001B[1;32m    102\u001B[0m             \u001B[0moperator_export_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOperatorExportTypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mONNX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m     _export(model, args, f, export_params, verbose, training, input_names, output_names,\n\u001B[0;32m--> 104\u001B[0;31m             operator_export_type=operator_export_type)\n\u001B[0m\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py\u001B[0m in \u001B[0;36m_export\u001B[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate)\u001B[0m\n\u001B[1;32m    285\u001B[0m     \u001B[0mdefer_weight_export\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexport_type\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mExportTypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPROTOBUF_FILE\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    286\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mexport_params\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 287\u001B[0;31m         \u001B[0mproto\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexport_map\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_export_onnx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_onnx_opset_version\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefer_weight_export\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moperator_export_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    288\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    289\u001B[0m         \u001B[0mproto\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexport_map\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_export_onnx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_onnx_opset_version\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moperator_export_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: ONNX export failed: Couldn't export operator aten::atan2\n\nDefined at:\n<ipython-input-8-6c7c0dfadad2>(108): forward\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/nn/modules/module.py(477): _slow_forward\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/nn/modules/module.py(487): __call__\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/jit/__init__.py(252): forward\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/nn/modules/module.py(489): __call__\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/jit/__init__.py(197): get_trace_graph\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py(192): _trace_and_get_graph_from_model\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py(224): _model_to_graph\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py(281): _export\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/utils.py(104): export\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/torch/onnx/__init__.py(27): export\n<ipython-input-20-ef10e6136362>(8): <module>\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3343): run_code\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3263): run_ast_nodes\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3072): run_cell_async\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/async_helpers.py(68): _pseudo_sync_runner\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/interactiveshell.py(2895): _run_cell\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/IPython/core/interactiveshell.py(2867): run_cell\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/zmqshell.py(536): run_cell\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/ipkernel.py(306): do_execute\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(162): _fake_ctx_run\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(234): wrapper\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/kernelbase.py(545): execute_request\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(162): _fake_ctx_run\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(234): wrapper\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/kernelbase.py(268): dispatch_shell\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(162): _fake_ctx_run\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(234): wrapper\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/kernelbase.py(365): process_one\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(775): run\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(162): _fake_ctx_run\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/gen.py(814): inner\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/ioloop.py(741): _run_callback\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/ioloop.py(688): <lambda>\n/root/anaconda3/envs/aaa/lib/python3.6/asyncio/events.py(145): _run\n/root/anaconda3/envs/aaa/lib/python3.6/asyncio/base_events.py(1462): _run_once\n/root/anaconda3/envs/aaa/lib/python3.6/asyncio/base_events.py(442): run_forever\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/tornado/platform/asyncio.py(199): start\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel/kernelapp.py(612): start\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/traitlets/config/application.py(664): launch_instance\n/root/anaconda3/envs/aaa/lib/python3.6/site-packages/ipykernel_launcher.py(16): <module>\n/root/anaconda3/envs/aaa/lib/python3.6/runpy.py(85): _run_code\n/root/anaconda3/envs/aaa/lib/python3.6/runpy.py(193): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%input : Float(1, 3, 256, 256)\n      %1 : Float(1, 1, 1, 5)\n      %2 : Float(1)\n      %3 : Float(1, 1, 5, 1)\n      %4 : Float(1)\n      %5 : Float(1, 1, 3, 3)\n      %6 : Float(1)\n      %7 : Float(1, 1, 3, 3)\n      %8 : Float(1)\n      %9 : Float(8, 1, 3, 3)\n      %10 : Float(8)) {\n  %11 : Long() = onnx::Constant[value={0}](), scope: CandyNet\n  %12 : Tensor = onnx::Shape(%input), scope: CandyNet\n  %13 : Long() = onnx::Gather[axis=0](%12, %11), scope: CandyNet\n  %14 : Float(1, 3, 256, 256) = onnx::Slice[axes=[0], ends=[9223372036854775807], starts=[0]](%input), scope: CandyNet\n  %15 : Float(1!, 1, 256, 256) = onnx::Slice[axes=[1], ends=[1], starts=[0]](%14), scope: CandyNet\n  %16 : Float(1, 3, 256, 256) = onnx::Slice[axes=[0], ends=[9223372036854775807], starts=[0]](%input), scope: CandyNet\n  %17 : Float(1!, 1, 256, 256) = onnx::Slice[axes=[1], ends=[2], starts=[1]](%16), scope: CandyNet\n  %18 : Float(1, 3, 256, 256) = onnx::Slice[axes=[0], ends=[9223372036854775807], starts=[0]](%input), scope: CandyNet\n  %19 : Float(1!, 1, 256, 256) = onnx::Slice[axes=[1], ends=[3], starts=[2]](%18), scope: CandyNet\n  %20 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 5], pads=[0, 2, 0, 2], strides=[1, 1]](%15, %1, %2), scope: CandyNet/Conv2d[gaussian_filter_horizontal]\n  %21 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 1], pads=[2, 0, 2, 0], strides=[1, 1]](%20, %3, %4), scope: CandyNet/Conv2d[gaussian_filter_vertical]\n  %22 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 5], pads=[0, 2, 0, 2], strides=[1, 1]](%17, %1, %2), scope: CandyNet/Conv2d[gaussian_filter_horizontal]\n  %23 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 1], pads=[2, 0, 2, 0], strides=[1, 1]](%22, %3, %4), scope: CandyNet/Conv2d[gaussian_filter_vertical]\n  %24 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 5], pads=[0, 2, 0, 2], strides=[1, 1]](%19, %1, %2), scope: CandyNet/Conv2d[gaussian_filter_horizontal]\n  %25 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 1], pads=[2, 0, 2, 0], strides=[1, 1]](%24, %3, %4), scope: CandyNet/Conv2d[gaussian_filter_vertical]\n  %26 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%21, %5, %6), scope: CandyNet/Conv2d[sobel_filter_horizontal]\n  %27 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%21, %7, %8), scope: CandyNet/Conv2d[sobel_filter_vertical]\n  %28 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%23, %5, %6), scope: CandyNet/Conv2d[sobel_filter_horizontal]\n  %29 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%23, %7, %8), scope: CandyNet/Conv2d[sobel_filter_vertical]\n  %30 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%25, %5, %6), scope: CandyNet/Conv2d[sobel_filter_horizontal]\n  %31 : Float(1, 1, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%25, %7, %8), scope: CandyNet/Conv2d[sobel_filter_vertical]\n  %32 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %33 : Float(1, 1, 256, 256) = onnx::Pow(%26, %32), scope: CandyNet\n  %34 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %35 : Float(1, 1, 256, 256) = onnx::Pow(%27, %34), scope: CandyNet\n  %36 : Float(1, 1, 256, 256) = onnx::Add(%33, %35), scope: CandyNet\n  %37 : Float(1, 1, 256, 256) = onnx::Sqrt(%36), scope: CandyNet\n  %38 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %39 : Float(1, 1, 256, 256) = onnx::Pow(%28, %38), scope: CandyNet\n  %40 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %41 : Float(1, 1, 256, 256) = onnx::Pow(%29, %40), scope: CandyNet\n  %42 : Float(1, 1, 256, 256) = onnx::Add(%39, %41), scope: CandyNet\n  %43 : Float(1, 1, 256, 256) = onnx::Sqrt(%42), scope: CandyNet\n  %44 : Float(1, 1, 256, 256) = onnx::Add(%37, %43), scope: CandyNet\n  %45 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %46 : Float(1, 1, 256, 256) = onnx::Pow(%30, %45), scope: CandyNet\n  %47 : Tensor = onnx::Constant[value={2}](), scope: CandyNet\n  %48 : Float(1, 1, 256, 256) = onnx::Pow(%31, %47), scope: CandyNet\n  %49 : Float(1, 1, 256, 256) = onnx::Add(%46, %48), scope: CandyNet\n  %50 : Float(1, 1, 256, 256) = onnx::Sqrt(%49), scope: CandyNet\n  %51 : Float(1, 1, 256, 256) = onnx::Add(%44, %50), scope: CandyNet\n  %52 : Float(1, 1, 256, 256) = onnx::Add(%27, %29), scope: CandyNet\n  %53 : Float(1, 1, 256, 256) = onnx::Add(%52, %31), scope: CandyNet\n  %54 : Float(1, 1, 256, 256) = onnx::Add(%26, %28), scope: CandyNet\n  %55 : Float(1, 1, 256, 256) = onnx::Add(%54, %30), scope: CandyNet\n  %56 : Float(1, 1, 256, 256) = aten::atan2(%53, %55), scope: CandyNet\n  %57 : Tensor = onnx::Constant[value={57.2958}]()\n  %58 : Tensor = onnx::Mul(%56, %57)\n  %59 : Tensor = onnx::Constant[value={180}]()\n  %60 : Tensor = onnx::Add(%58, %59)\n  %61 : Tensor = onnx::Constant[value={45}]()\n  %62 : Tensor = onnx::Div(%60, %61)\n  %63 : Float(1, 1, 256, 256) = aten::round(%62), scope: CandyNet\n  %64 : Tensor = onnx::Constant[value={45}]()\n  %65 : Tensor = onnx::Mul(%63, %64)\n  %66 : Tensor = onnx::Constant[value={45}]()\n  %67 : Tensor = onnx::Div(%65, %66)\n  %68 : Long() = onnx::Constant[value={8}](), scope: CandyNet\n  %69 : Float(1, 1, 256, 256) = aten::remainder(%67, %68), scope: CandyNet\n  %70 : Long() = onnx::Constant[value={2}](), scope: CandyNet\n  %71 : Tensor = onnx::Shape(%69), scope: CandyNet\n  %72 : Long() = onnx::Gather[axis=0](%71, %70), scope: CandyNet\n  %73 : Long() = onnx::Constant[value={3}](), scope: CandyNet\n  %74 : Tensor = onnx::Shape(%69), scope: CandyNet\n  %75 : Long() = onnx::Gather[axis=0](%74, %73), scope: CandyNet\n  %76 : Long() = onnx::Constant[value={1}](), scope: CandyNet\n  %77 : Tensor = onnx::Unsqueeze[axes=[0]](%13)\n  %78 : Tensor = onnx::Unsqueeze[axes=[0]](%76)\n  %79 : Tensor = onnx::Unsqueeze[axes=[0]](%72)\n  %80 : Tensor = onnx::Unsqueeze[axes=[0]](%75)\n  %81 : Tensor = onnx::Concat[axis=0](%77, %78, %79, %80)\n  %82 : Float(1, 1, 256, 256) = onnx::ConstantFill[dtype=1, input_as_shape=1, value=1](%81), scope: CandyNet\n  %83 : Long() = onnx::Constant[value={1}](), scope: CandyNet\n  %84 : Tensor = onnx::Unsqueeze[axes=[0]](%13)\n  %85 : Tensor = onnx::Unsqueeze[axes=[0]](%83)\n  %86 : Tensor = onnx::Unsqueeze[axes=[0]](%72)\n  %87 : Tensor = onnx::Unsqueeze[axes=[0]](%75)\n  %88 : Tensor = onnx::Concat[axis=0](%84, %85, %86, %87)\n  %89 : Float(1, 1, 256, 256) = onnx::ConstantFill[dtype=1, input_as_shape=1, value=1](%88), scope: CandyNet\n  %90 : Tensor = onnx::Unsqueeze[axes=[1]](%82), scope: CandyNet\n  %91 : Tensor = onnx::Unsqueeze[axes=[1]](%89), scope: CandyNet\n  %92 : Float(1, 2, 1, 256, 256) = onnx::Concat[axis=1](%90, %91), scope: CandyNet\n  %93 : Float(1, 1, 256, 256), %94 : Long(1, 1, 256, 256) = onnx::ATen[dim=1, keepdim=0, operator=\"min\"](%92), scope: CandyNet\n  %95 : Tensor = onnx::Constant[value={0}](), scope: CandyNet\n  %96 : Byte(1, 1, 256, 256) = onnx::Greater(%93, %95), scope: CandyNet\n  %97 : Long() = onnx::Constant[value={0}](), scope: CandyNet\n  %98 : Byte(1, 1, 256, 256) = onnx::Equal(%96, %97), scope: CandyNet\n  %99 : Float() = onnx::Constant[value={0}]()\n  %100 : Byte(1, 1, 256, 256) = onnx::Cast[to=2](%98), scope: CandyNet\n  %101 : Long() = onnx::Constant[value={0}](), scope: CandyNet\n  %102 : Float(1, 1, 256, 256) = onnx::ATen[operator=\"index_put\"](%51, %100, %99, %101), scope: CandyNet\n  %103 : Tensor = onnx::Constant[value={3}](), scope: CandyNet\n  %104 : Byte(1, 1, 256, 256) = onnx::Less(%102, %103), scope: CandyNet\n  %105 : Float() = onnx::Constant[value={0}]()\n  %106 : Byte(1, 1, 256, 256) = onnx::Cast[to=2](%104), scope: CandyNet\n  %107 : Long() = onnx::Constant[value={0}](), scope: CandyNet\n  %108 : Float(1, 1, 256, 256) = onnx::ATen[operator=\"index_put\"](%102, %106, %105, %107), scope: CandyNet\n  return (%108);\n}\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1,3,256,256)\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        candy,\n",
    "        x,\n",
    "        'candy.onnx',\n",
    "        #opset_version=11,\n",
    "        input_names=['input'],\n",
    "        #output_names=['output']\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 0.0000, 25.9050,  0.0000,  ...,  0.0000,  0.0000, 17.5363],\n          [ 0.0000,  0.0000, 31.3237,  ..., 27.4972,  0.0000, 19.5156],\n          [30.4530, 40.9091,  0.0000,  ...,  0.0000, 17.6542,  0.0000],\n          ...,\n          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 17.8266],\n          [24.5876, 30.4273, 34.9075,  ...,  0.0000, 20.9378, 15.7724],\n          [23.1771,  0.0000,  0.0000,  ...,  0.0000, 14.5815,  0.0000]]]],\n       grad_fn=<IndexPutBackward>)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model = ConvDown(3,2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 256, 256])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "ConvDown(\n  (body): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): ReLU()\n  )\n  (tail): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        x,\n",
    "        'ConvDown.onnx',\n",
    "        #opset_version=11,\n",
    "        input_names=['input'],\n",
    "        output_names=['output']\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = ConvUp(3,2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "x = torch.randn(1,3,128,128)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        x,\n",
    "        'ConvUp.onnx',\n",
    "        #opset_version=11,\n",
    "        input_names=['input'],\n",
    "        output_names=['output']\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-aaa-py",
   "language": "python",
   "display_name": "Python [conda env:aaa] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
