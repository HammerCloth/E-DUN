{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 466,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(1, 3, 20, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.denoisingModule import EncodingBlock, EncodingBlockEnd, DecodingBlock, DecodingBlockEnd\n",
    "from models.textureReconstructionModule import ConvDown, ConvUp\n",
    "\n",
    "\n",
    "def make_model(args, parent=False):\n",
    "    return E_DUN(args)\n",
    "\n",
    "\n",
    "class E_DUN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(E_DUN, self).__init__()\n",
    "\n",
    "        self.channel0 = args.n_colors  # channel的数量\n",
    "        self.up_factor = args.scale[0]  # 放大倍数\n",
    "        self.patch_size = args.patch_size\n",
    "        self.batch_size = int(args.batch_size / args.n_GPUs)\n",
    "\n",
    "        self.Encoding_block1 = EncodingBlock(64)\n",
    "        self.Encoding_block2 = EncodingBlock(64)\n",
    "        self.Encoding_block3 = EncodingBlock(64)\n",
    "        self.Encoding_block4 = EncodingBlock(64)\n",
    "\n",
    "        self.Encoding_block_end = EncodingBlockEnd(64)\n",
    "\n",
    "        self.Decoding_block1 = DecodingBlock(256)\n",
    "        self.Decoding_block2 = DecodingBlock(256)\n",
    "        self.Decoding_block3 = DecodingBlock(256)\n",
    "        self.Decoding_block4 = DecodingBlock(256)\n",
    "\n",
    "        self.feature_decoding_end = DecodingBlockEnd(256)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        self.construction = nn.Conv2d(64, 3, 3, padding=1)\n",
    "\n",
    "        G0 = 64\n",
    "        kSize = 3\n",
    "        T = 4\n",
    "        self.Fe_e = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                *[\n",
    "                    nn.Conv2d(3, G0, kSize, padding=(kSize - 1) // 2, stride=1),\n",
    "                    nn.Conv2d(G0, G0, kSize, padding=(kSize - 1) // 2, stride=1)\n",
    "                ]\n",
    "            ) for _ in range(T)]\n",
    "        )\n",
    "\n",
    "        self.RNNF = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                *[\n",
    "                    nn.Conv2d((i + 2) * G0, G0, 1, padding=0, stride=1),\n",
    "                    nn.Conv2d(G0, G0, kSize, padding=(kSize - 1) // 2, stride=1),\n",
    "                    self.act,\n",
    "                    nn.Conv2d(64, 3, 3, padding=1)\n",
    "                ]\n",
    "            ) for i in range(T)]\n",
    "        )\n",
    "\n",
    "        self.Fe_f = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                *[\n",
    "                    nn.Conv2d((2 * i + 3) * G0, G0, 1, padding=0, stride=1)\n",
    "                ]\n",
    "            ) for i in range(T - 1)]\n",
    "        )\n",
    "\n",
    "        # 纹理重构模块\n",
    "        self.eta = nn.ParameterList([nn.Parameter(torch.tensor(0.5)) for _ in range(T)])\n",
    "        self.delta = nn.ParameterList([nn.Parameter(torch.tensor(0.1)) for _ in range(T)])\n",
    "        self.conv_up = ConvUp(3, self.up_factor)\n",
    "        self.conv_down = ConvDown(3, self.up_factor)\n",
    "\n",
    "        # candy算子不需要迭代内部系数\n",
    "        self.candy = CandyNet(3)\n",
    "        for para in self.candy.parameters():\n",
    "            para.requires_grad = False\n",
    "\n",
    "    def forward(self, y):  # [batch_size ,3 ,7 ,270 ,480] ;\n",
    "\n",
    "        fea_list = []\n",
    "        V_list = []\n",
    "        outs = []\n",
    "        x_texture = []\n",
    "        x_texture.append(torch.nn.functional.interpolate(\n",
    "            y, scale_factor=self.up_factor, mode='bilinear', align_corners=False))\n",
    "        x_edge = self.candy(x_texture[0])\n",
    "        x = (x_edge + x_texture[0])  # 这里可以增加一些倍数，直接相加可能会存在问题\n",
    "\n",
    "        for i in range(len(self.Fe_e)):\n",
    "            # --------------------denoising module------------------------\n",
    "            fea = self.Fe_e[i](x_texture[i])\n",
    "            fea_list.append(fea)\n",
    "            if i != 0:\n",
    "                fea = self.Fe_f[i - 1](torch.cat(fea_list, 1))\n",
    "            encode0, down0 = self.Encoding_block1(fea)\n",
    "            encode1, down1 = self.Encoding_block2(down0)\n",
    "            encode2, down2 = self.Encoding_block3(down1)\n",
    "            encode3, down3 = self.Encoding_block4(down2)\n",
    "\n",
    "            media_end = self.Encoding_block_end(down3)\n",
    "\n",
    "            decode3 = self.Decoding_block1(media_end, encode3)\n",
    "            decode2 = self.Decoding_block2(decode3, encode2)\n",
    "            decode1 = self.Decoding_block3(decode2, encode1)\n",
    "            decode0 = self.feature_decoding_end(decode1, encode0)\n",
    "\n",
    "            fea_list.append(decode0)\n",
    "            V_list.append(decode0)\n",
    "            if i == 0:\n",
    "                decode0 = self.construction(self.act(decode0))\n",
    "            else:\n",
    "                decode0 = self.RNNF[i - 1](torch.cat(V_list, 1))\n",
    "            v = x_texture[i] + decode0\n",
    "\n",
    "            # # --------------------texture module--------------------------\n",
    "            x_texture.append(x_texture[i] - self.delta[i] * (\n",
    "                    self.conv_up(self.conv_down(x) - y) + self.eta[i] * (x - v)))\n",
    "\n",
    "            # # -----------------------edge module--------------------------\n",
    "            x_edge = (self.candy(x))  # 这里对代码进行了置换\n",
    "            x = x_edge + x_texture[i + 1]  # 这里可以增加一些倍数，直接相加可能会存在问题\n",
    "            #\n",
    "            outs.append(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "outputs": [],
   "source": [
    "class args:\n",
    "    def __init__(self):\n",
    "        self.n_colors = 3\n",
    "        self.scale = [2]\n",
    "        self.patch_size = 1\n",
    "        self.batch_size = 1\n",
    "        self.n_GPUs = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = args()\n",
    "test.n_colors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "outputs": [
    {
     "data": {
      "text/plain": "E_DUN(\n  (Encoding_block1): EncodingBlock(\n    (body): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (down): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n  )\n  (Encoding_block2): EncodingBlock(\n    (body): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (down): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n  )\n  (Encoding_block3): EncodingBlock(\n    (body): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (down): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n  )\n  (Encoding_block4): EncodingBlock(\n    (body): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (down): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n  )\n  (Encoding_block_end): EncodingBlockEnd(\n    (head): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n    )\n    (body): Sequential(\n      (0): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (1): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (5): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (6): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (7): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (8): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (9): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (10): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (11): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (12): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (13): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (14): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (15): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (16): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (17): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (tail): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (Decoding_block1): DecodingBlock(\n    (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n    (body): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (Decoding_block2): DecodingBlock(\n    (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n    (body): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (Decoding_block3): DecodingBlock(\n    (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n    (body): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (Decoding_block4): DecodingBlock(\n    (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n    (body): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (feature_decoding_end): DecodingBlockEnd(\n    (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (act): ReLU()\n    (body): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (3): ResBlock(\n        (body): Sequential(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n  )\n  (act): ReLU()\n  (construction): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Fe_e): ModuleList(\n    (0): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (1): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (2): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (3): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (RNNF): ModuleList(\n    (0): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): ReLU()\n      (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (1): Sequential(\n      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): ReLU()\n      (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (2): Sequential(\n      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): ReLU()\n      (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (3): Sequential(\n      (0): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): ReLU()\n      (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (Fe_f): ModuleList(\n    (0): Sequential(\n      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (1): Sequential(\n      (0): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (2): Sequential(\n      (0): Conv2d(448, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (eta): ParameterList(\n      (0): Parameter containing: [torch.FloatTensor of size ]\n      (1): Parameter containing: [torch.FloatTensor of size ]\n      (2): Parameter containing: [torch.FloatTensor of size ]\n      (3): Parameter containing: [torch.FloatTensor of size ]\n  )\n  (delta): ParameterList(\n      (0): Parameter containing: [torch.FloatTensor of size ]\n      (1): Parameter containing: [torch.FloatTensor of size ]\n      (2): Parameter containing: [torch.FloatTensor of size ]\n      (3): Parameter containing: [torch.FloatTensor of size ]\n  )\n  (conv_up): ConvUp(\n    (body): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n    )\n    (tail): Sequential(\n      (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (conv_down): ConvDown(\n    (body): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n    )\n    (tail): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (candy): CandyNet(\n    (gaussian_filter_horizontal): Conv2d(1, 1, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n    (gaussian_filter_vertical): Conv2d(1, 1, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n    (sobel_filter_horizontal): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (sobel_filter_vertical): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (directional_filter): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n)"
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = E_DUN(test)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "outputs": [],
   "source": [
    "y = model(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 40, 40])"
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "loss_function = nn.L1Loss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "outputs": [],
   "source": [
    "z = torch.rand(1, 3, 40, 40)\n",
    "loss = loss_function(y, z)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "outputs": [],
   "source": [
    "\n",
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import signal as signal\n",
    "\n",
    "\n",
    "class CandyNet(nn.Module):\n",
    "    def __init__(self, threshold=10.0, use_cuda=False):\n",
    "        super(CandyNet, self).__init__()\n",
    "\n",
    "        self.threshold = threshold\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        filter_size = 5\n",
    "        generated_filters = signal.gaussian(filter_size, std=1.0).reshape([1, filter_size])\n",
    "\n",
    "        self.gaussian_filter_horizontal = nn.Conv2d(1, 1, kernel_size=(1, filter_size), padding=(0, filter_size // 2))\n",
    "        self.gaussian_filter_horizontal.weight.data.copy_(torch.from_numpy(generated_filters))\n",
    "        self.gaussian_filter_horizontal.bias.data.copy_(torch.from_numpy(np.array([0.0])))\n",
    "\n",
    "        self.gaussian_filter_vertical = nn.Conv2d(1, 1, kernel_size=(filter_size, 1), padding=(filter_size // 2, 0))\n",
    "        self.gaussian_filter_vertical.weight.data.copy_(torch.from_numpy(generated_filters.T))\n",
    "        self.gaussian_filter_vertical.bias.data.copy_(torch.from_numpy(np.array([0.0])))\n",
    "\n",
    "        sobel_filter = np.array([[1, 0, -1],\n",
    "                                 [2, 0, -2],\n",
    "                                 [1, 0, -1]])\n",
    "\n",
    "        self.sobel_filter_horizontal = nn.Conv2d(1, 1, kernel_size=sobel_filter.shape,\n",
    "                                                 padding=sobel_filter.shape[0] // 2)\n",
    "        self.sobel_filter_horizontal.weight.data.copy_(torch.from_numpy(sobel_filter))\n",
    "        self.sobel_filter_horizontal.bias.data.copy_(torch.from_numpy(np.array([0.0])))\n",
    "\n",
    "        self.sobel_filter_vertical = nn.Conv2d(1, 1, kernel_size=sobel_filter.shape, padding=sobel_filter.shape[0] // 2)\n",
    "        self.sobel_filter_vertical.weight.data.copy_(torch.from_numpy(sobel_filter.T))\n",
    "        self.sobel_filter_vertical.bias.data.copy_(torch.from_numpy(np.array([0.0])))\n",
    "\n",
    "        # filters were flipped manually\n",
    "        filter_0 = np.array([[0, 0, 0],\n",
    "                             [0, 1, -1],\n",
    "                             [0, 0, 0]])\n",
    "\n",
    "        filter_45 = np.array([[0, 0, 0],\n",
    "                              [0, 1, 0],\n",
    "                              [0, 0, -1]])\n",
    "\n",
    "        filter_90 = np.array([[0, 0, 0],\n",
    "                              [0, 1, 0],\n",
    "                              [0, -1, 0]])\n",
    "\n",
    "        filter_135 = np.array([[0, 0, 0],\n",
    "                               [0, 1, 0],\n",
    "                               [-1, 0, 0]])\n",
    "\n",
    "        filter_180 = np.array([[0, 0, 0],\n",
    "                               [-1, 1, 0],\n",
    "                               [0, 0, 0]])\n",
    "\n",
    "        filter_225 = np.array([[-1, 0, 0],\n",
    "                               [0, 1, 0],\n",
    "                               [0, 0, 0]])\n",
    "\n",
    "        filter_270 = np.array([[0, -1, 0],\n",
    "                               [0, 1, 0],\n",
    "                               [0, 0, 0]])\n",
    "\n",
    "        filter_315 = np.array([[0, 0, -1],\n",
    "                               [0, 1, 0],\n",
    "                               [0, 0, 0]])\n",
    "\n",
    "        all_filters = np.stack(\n",
    "            [filter_0, filter_45, filter_90, filter_135, filter_180, filter_225, filter_270, filter_315])\n",
    "\n",
    "        self.directional_filter = nn.Conv2d(1, 8, kernel_size=filter_0.shape, padding=filter_0.shape[-1] // 2)\n",
    "        self.directional_filter.weight.data.copy_(torch.from_numpy(all_filters[:, None, ...]))\n",
    "        self.directional_filter.bias.data.copy_(torch.from_numpy(np.zeros(shape=(all_filters.shape[0],))))\n",
    "\n",
    "    def forward(self, img):  # (batch,channel,height, width)\n",
    "\n",
    "        batch = img.shape[0]\n",
    "        img_r = img[:, 0:1]  # batch,1,height, width\n",
    "        img_g = img[:, 1:2]  # batch,1,height, width\n",
    "        img_b = img[:, 2:3]  # batch,1,height, width\n",
    "\n",
    "        blur_horizontal_r = self.gaussian_filter_horizontal(img_r)  # batch,1,height,width\n",
    "        blurred_img_r = self.gaussian_filter_vertical(blur_horizontal_r)  # batch,1,height,width\n",
    "        blur_horizontal_g = self.gaussian_filter_horizontal(img_g)  # batch,1,height,width\n",
    "        blurred_img_g = self.gaussian_filter_vertical(blur_horizontal_g)  # batch,1,height,width\n",
    "        blur_horizontal_b = self.gaussian_filter_horizontal(img_b)  # batch,1,height,width\n",
    "        blurred_img_b = self.gaussian_filter_vertical(blur_horizontal_b)  # batch,1,height,width\n",
    "\n",
    "        blurred_img_ = torch.stack([blurred_img_r, blurred_img_g, blurred_img_b], dim=1)  # batch,1,height,width\n",
    "        blurred_img = torch.stack([torch.squeeze(blurred_img_)])  # batch,1,height,width\n",
    "\n",
    "        grad_x_r = self.sobel_filter_horizontal(blurred_img_r)  # batch,1,height,width\n",
    "        grad_y_r = self.sobel_filter_vertical(blurred_img_r)  # batch,1,height,width\n",
    "        grad_x_g = self.sobel_filter_horizontal(blurred_img_g)  # batch,1,height,width\n",
    "        grad_y_g = self.sobel_filter_vertical(blurred_img_g)  # batch,1,height,width\n",
    "        grad_x_b = self.sobel_filter_horizontal(blurred_img_b)  # batch,1,height,width\n",
    "        grad_y_b = self.sobel_filter_vertical(blurred_img_b)  # batch,1,height,width\n",
    "\n",
    "        # COMPUTE THICK EDGES\n",
    "        grad_mag_1 = torch.sqrt(grad_x_r ** 2 + grad_y_r ** 2)  # batch,1,height,width\n",
    "        grad_mag_2 = grad_mag_1 + torch.sqrt(grad_x_g ** 2 + grad_y_g ** 2)  # batch,1,height,width\n",
    "        grad_mag = grad_mag_2 + torch.sqrt(grad_x_b ** 2 + grad_y_b ** 2)  # batch,1,height,width\n",
    "        grad_orientation_1 = (  # batch,1,height,width\n",
    "                torch.atan2(grad_y_r + grad_y_g + grad_y_b, grad_x_r + grad_x_g + grad_x_b) * (180.0 / 3.14159))\n",
    "        grad_orientation_2 = grad_orientation_1 + 180.0  # batch,1,height,width\n",
    "        grad_orientation = torch.round(grad_orientation_2 / 45.0) * 45.0  # batch,1,height,width\n",
    "\n",
    "        # THIN EDGES (NON-MAX SUPPRESSION)\n",
    "\n",
    "        all_filtered = self.directional_filter(grad_mag)  # batch,8,height,width\n",
    "        inidices_positive = (grad_orientation / 45) % 8  # batch,1,height,width\n",
    "        inidices_negative = ((grad_orientation / 45) + 4) % 8  # batch,1,height,width\n",
    "\n",
    "        height = inidices_positive.size()[2]\n",
    "        width = inidices_positive.size()[3]\n",
    "        pixel_count = height * width\n",
    "\n",
    "        pixel_range = torch.FloatTensor([range(pixel_count)])  # batch,pixel_range\n",
    "        if self.use_cuda:\n",
    "            pixel_range = torch.cuda.FloatTensor([range(pixel_count)])\n",
    "\n",
    "        indices = (  # batch,pixel_range\n",
    "                inidices_positive.view(\n",
    "                    inidices_positive.shape[0],\n",
    "                    pixel_count).data * pixel_count + pixel_range)\n",
    "\n",
    "        channel_select_filtered_positive = torch.ones(batch, 1, height, width)  # batch, 1, height, width\n",
    "        for i in range(batch):\n",
    "            channel_select_filtered_positive_temp = all_filtered[i].view(-1)[indices[i].long()].view(1, height, width)\n",
    "            channel_select_filtered_positive[i] = channel_select_filtered_positive_temp\n",
    "\n",
    "        indices = (  # batch,pixel_range\n",
    "                inidices_negative.view(\n",
    "                    inidices_negative.shape[0],\n",
    "                    pixel_count).data * pixel_count + pixel_range)\n",
    "\n",
    "        channel_select_filtered_negative = torch.ones(batch, 1, height, width)  # batch, 1, height, width\n",
    "        for i in range(batch):\n",
    "            channel_select_filtered_negative_temp = all_filtered[i].view(-1)[indices[i].long()].view(1, height, width)\n",
    "            channel_select_filtered_negative[i] = channel_select_filtered_negative_temp\n",
    "\n",
    "        channel_select_filtered = torch.stack(  # batch, 2, height, width\n",
    "            [channel_select_filtered_positive, channel_select_filtered_negative], dim=1)\n",
    "\n",
    "        is_max = channel_select_filtered.min(dim=1)[0] > 0.0\n",
    "\n",
    "        thin_edges = grad_mag.clone()\n",
    "        thin_edges[is_max == 0] = 0.0\n",
    "\n",
    "        # THRESHOLD\n",
    "\n",
    "        thresholded = thin_edges.clone()\n",
    "        thresholded[thin_edges < self.threshold] = 0.0\n",
    "\n",
    "        early_threshold = grad_mag.clone()\n",
    "        early_threshold[grad_mag < self.threshold] = 0.0\n",
    "\n",
    "        # assert grad_mag.size() == grad_orientation.size() == thin_edges.size() == thresholded.size() == early_threshold.size()\n",
    "\n",
    "        return thresholded\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    CandyNet()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyixiong/miniforge3/envs/deepLeaning/lib/python3.9/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([1, 3, 20, 20])) that is different to the input size (torch.Size([1, 1, 20, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "candy = CandyNet(3)\n",
    "y = candy(x)\n",
    "loss = loss_function(y, x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "outputs": [],
   "source": [
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
